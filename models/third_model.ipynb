{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ML Model with Historical Features for Flight Delay Prediction\n",
    "\n",
    "Uses ML algorithms with historical statistics as features to predict at booking time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.metrics import mean_absolute_error, r2_score, mean_squared_error\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv(\"../files/flights.csv\", low_memory=False)\n",
    "df = raw_df[raw_df.ARRIVAL_DELAY.notna()].copy()\n",
    "\n",
    "print(f\"Total flights: {len(df):,}\")\n",
    "print(f\"Columns: {df.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculate Historical Statistics\n",
    "\n",
    "These will be features the ML model can use at prediction time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate historical averages by route/airline/month\n",
    "route_airline_stats = df.groupby(['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'MONTH'])['ARRIVAL_DELAY'].agg([\n",
    "    ('hist_avg_delay', 'mean'),\n",
    "    ('hist_std_delay', 'std'),\n",
    "    ('hist_count', 'count')\n",
    "]).reset_index()\n",
    "\n",
    "print(f\"\\nRoute/Airline/Month combinations: {len(route_airline_stats):,}\")\n",
    "\n",
    "# Calculate by airline\n",
    "airline_stats = df.groupby('AIRLINE')['ARRIVAL_DELAY'].agg([\n",
    "    ('airline_avg_delay', 'mean')\n",
    "]).reset_index()\n",
    "\n",
    "# Calculate by route (any airline)\n",
    "route_stats = df.groupby(['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'MONTH'])['ARRIVAL_DELAY'].agg([\n",
    "    ('route_avg_delay', 'mean')\n",
    "]).reset_index()\n",
    "\n",
    "# Calculate by origin airport + month\n",
    "origin_stats = df.groupby(['ORIGIN_AIRPORT', 'MONTH'])['ARRIVAL_DELAY'].agg([\n",
    "    ('origin_avg_delay', 'mean')\n",
    "]).reset_index()\n",
    "\n",
    "# Calculate by destination airport + month  \n",
    "dest_stats = df.groupby(['DESTINATION_AIRPORT', 'MONTH'])['ARRIVAL_DELAY'].agg([\n",
    "    ('dest_avg_delay', 'mean')\n",
    "]).reset_index()\n",
    "\n",
    "print(f\"Airline stats: {len(airline_stats)}\")\n",
    "print(f\"Route stats: {len(route_stats):,}\")\n",
    "print(f\"Origin airport stats: {len(origin_stats):,}\")\n",
    "print(f\"Destination airport stats: {len(dest_stats):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Merge Historical Features with Data\n",
    "\n",
    "This simulates what we'd do at prediction time: look up historical stats."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select columns\n",
    "cols = ['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'MONTH', 'DAY_OF_WEEK', \n",
    "        'SCHEDULED_DEPARTURE', 'DISTANCE', 'ARRIVAL_DELAY']\n",
    "\n",
    "available_cols = [col for col in cols if col in df.columns]\n",
    "df_model = df[available_cols].copy()\n",
    "\n",
    "# Merge historical stats\n",
    "df_model = df_model.merge(route_airline_stats, \n",
    "                          on=['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'MONTH'], \n",
    "                          how='left')\n",
    "df_model = df_model.merge(airline_stats, on='AIRLINE', how='left')\n",
    "df_model = df_model.merge(route_stats, \n",
    "                          on=['ORIGIN_AIRPORT', 'DESTINATION_AIRPORT', 'MONTH'], \n",
    "                          how='left')\n",
    "df_model = df_model.merge(origin_stats, on=['ORIGIN_AIRPORT', 'MONTH'], how='left')\n",
    "df_model = df_model.merge(dest_stats, on=['DESTINATION_AIRPORT', 'MONTH'], how='left')\n",
    "\n",
    "print(f\"\\nData with historical features: {df_model.shape}\")\n",
    "print(f\"New columns: {[c for c in df_model.columns if 'hist_' in c or '_avg_' in c or '_std_' in c]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time-based features\n",
    "if 'SCHEDULED_DEPARTURE' in df_model.columns:\n",
    "    df_model['DEPARTURE_HOUR'] = df_model['SCHEDULED_DEPARTURE'] // 100\n",
    "    df_model['IS_MORNING'] = (df_model['DEPARTURE_HOUR'] < 12).astype(int)\n",
    "    df_model['IS_EVENING'] = (df_model['DEPARTURE_HOUR'] >= 18).astype(int)\n",
    "\n",
    "if 'DAY_OF_WEEK' in df_model.columns:\n",
    "    df_model['IS_WEEKEND'] = (df_model['DAY_OF_WEEK'] >= 6).astype(int)\n",
    "\n",
    "if 'MONTH' in df_model.columns:\n",
    "    df_model['IS_SUMMER'] = df_model['MONTH'].isin([6, 7, 8]).astype(int)\n",
    "    df_model['IS_HOLIDAY'] = df_model['MONTH'].isin([11, 12]).astype(int)\n",
    "\n",
    "if 'DISTANCE' in df_model.columns:\n",
    "    df_model['IS_SHORT'] = (df_model['DISTANCE'] < 500).astype(int)\n",
    "    df_model['IS_LONG'] = (df_model['DISTANCE'] > 2000).astype(int)\n",
    "\n",
    "# Fill NaN in historical stats with overall means\n",
    "for col in ['hist_avg_delay', 'hist_std_delay', 'airline_avg_delay', \n",
    "            'route_avg_delay', 'origin_avg_delay', 'dest_avg_delay']:\n",
    "    if col in df_model.columns:\n",
    "        df_model[col] = df_model[col].fillna(df_model['ARRIVAL_DELAY'].mean())\n",
    "\n",
    "if 'hist_count' in df_model.columns:\n",
    "    df_model['hist_count'] = df_model['hist_count'].fillna(0)\n",
    "\n",
    "print(f\"\\nFeature engineering complete\")\n",
    "print(f\"Total columns: {len(df_model.columns)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample and Split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample 10k\n",
    "sample_size = min(10000, len(df_model))\n",
    "df_sample = df_model.sample(n=sample_size, random_state=42)\n",
    "\n",
    "print(f\"Sample size: {len(df_sample):,}\")\n",
    "\n",
    "# Drop columns not needed for prediction\n",
    "drop_cols = ['ARRIVAL_DELAY', 'SCHEDULED_DEPARTURE']\n",
    "X = df_sample.drop(drop_cols, axis=1, errors='ignore')\n",
    "y = df_sample['ARRIVAL_DELAY']\n",
    "\n",
    "# Identify categorical vs numeric\n",
    "categorical_features = ['AIRLINE', 'ORIGIN_AIRPORT', 'DESTINATION_AIRPORT']\n",
    "numeric_features = [col for col in X.columns if col not in categorical_features]\n",
    "\n",
    "print(f\"\\nCategorical features: {categorical_features}\")\n",
    "print(f\"Numeric features ({len(numeric_features)}): {numeric_features}\")\n",
    "\n",
    "# Split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)\n",
    "print(f\"\\nTrain: {len(X_train):,} | Test: {len(X_test):,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Models with LabelEncoder for Categories\n",
    "\n",
    "XGBoost/LightGBM handle categorical features natively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
     "from sklearn.preprocessing import LabelEncoder\n",
     "\n",
     "# Encode categorical features (handle unknown values)\n",
     "encoders = {}\n",
     "X_train_encoded = X_train.copy()\n",
     "X_test_encoded = X_test.copy()\n",
     "\n",
     "for col in categorical_features:\n",
     "    encoders[col] = LabelEncoder()\n",
     "    # Fit on all unique values from both train and test\n",
     "    all_values = pd.concat([X_train[col], X_test[col]]).unique()\n",
     "    encoders[col].fit(all_values.astype(str))\n",
     "    X_train_encoded[col] = encoders[col].transform(X_train[col].astype(str))\n",
     "    X_test_encoded[col] = encoders[col].transform(X_test[col].astype(str))\n",
     "\n",
     "print(\"✓ Categorical features encoded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = {\n",
    "    'XGBoost': xgb.XGBRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        min_child_weight=3,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    'LightGBM': lgb.LGBMRegressor(\n",
    "        n_estimators=300,\n",
    "        learning_rate=0.05,\n",
    "        max_depth=6,\n",
    "        num_leaves=40,\n",
    "        min_child_samples=15,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_alpha=0.3,\n",
    "        reg_lambda=0.8,\n",
    "        random_state=42,\n",
    "        n_jobs=-1,\n",
    "        verbosity=-1\n",
    "    ),\n",
    "    'Random Forest': RandomForestRegressor(\n",
    "        n_estimators=200,\n",
    "        max_depth=12,\n",
    "        min_samples_split=15,\n",
    "        min_samples_leaf=8,\n",
    "        max_features=0.5,\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "}\n",
    "\n",
    "print(\"Training models...\\n\")\n",
    "results = []\n",
    "\n",
    "for name, model in models.items():\n",
    "    print(f\"[{name}]\")\n",
    "    print(\"  Training...\", end=\" \")\n",
    "    model.fit(X_train_encoded, y_train)\n",
    "    print(\"✓\")\n",
    "    \n",
    "    print(\"  Cross-validating...\", end=\" \")\n",
    "    kfold = KFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    cv_scores = cross_val_score(model, X_train_encoded, y_train, cv=kfold, scoring='r2', n_jobs=-1)\n",
    "    print(\"✓\")\n",
    "    \n",
    "    y_pred_train = model.predict(X_train_encoded)\n",
    "    y_pred_test = model.predict(X_test_encoded)\n",
    "    \n",
    "    train_r2 = r2_score(y_train, y_pred_train) * 100\n",
    "    test_r2 = r2_score(y_test, y_pred_test) * 100\n",
    "    test_mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    test_rmse = np.sqrt(mean_squared_error(y_test, y_pred_test))\n",
    "    \n",
    "    results.append({\n",
    "        'Model': name,\n",
    "        'CV_R2': cv_scores.mean() * 100,\n",
    "        'CV_Std': cv_scores.std() * 100,\n",
    "        'Train_R2': train_r2,\n",
    "        'Test_R2': test_r2,\n",
    "        'Test_MAE': test_mae,\n",
    "        'Test_RMSE': test_rmse,\n",
    "        'Overfitting': train_r2 - test_r2,\n",
    "        'predictions': y_pred_test,\n",
    "        'model_obj': model\n",
    "    })\n",
    "    print(f\"  Test R²: {test_r2:.2f}% | MAE: {test_mae:.2f}\\n\")\n",
    "\n",
    "print(\"✓ All models trained\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame(results).sort_values('Test_R2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL COMPARISON\")\n",
    "print(\"=\"*80)\n",
    "print(\"\\n{:<20} {:>10} {:>10} {:>10} {:>12}\".format(\n",
    "    \"Model\", \"CV R²\", \"Test R²\", \"Test MAE\", \"Overfitting\"\n",
    "))\n",
    "print(\"-\" * 70)\n",
    "\n",
    "for _, row in results_df.iterrows():\n",
    "    print(\"{:<20} {:>9.2f}% {:>9.2f}% {:>9.2f} {:>11.2f}%\".format(\n",
    "        row['Model'], row['CV_R2'], row['Test_R2'], row['Test_MAE'], row['Overfitting']\n",
    "    ))\n",
    "\n",
    "best = results_df.iloc[0]\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"BEST MODEL: {best['Model']}\")\n",
    "print(\"=\"*80)\n",
    "print(f\"Test R²:  {best['Test_R2']:.2f}%\")\n",
    "print(f\"Test MAE: {best['Test_MAE']:.2f} minutes\")\n",
    "print(f\"Test RMSE: {best['Test_RMSE']:.2f} minutes\")\n",
    "print(f\"CV R²: {best['CV_R2']:.2f}% ± {best['CV_Std']:.2f}%\")\n",
    "print(f\"Overfitting Gap: {best['Overfitting']:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model comparison\n",
    "fig = go.Figure()\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='CV R²',\n",
    "    x=results_df['Model'],\n",
    "    y=results_df['CV_R2'],\n",
    "    error_y=dict(type='data', array=results_df['CV_Std'])\n",
    "))\n",
    "\n",
    "fig.add_trace(go.Bar(\n",
    "    name='Test R²',\n",
    "    x=results_df['Model'],\n",
    "    y=results_df['Test_R2']\n",
    "))\n",
    "\n",
    "fig.update_layout(\n",
    "    title='Model Comparison',\n",
    "    xaxis_title='Model',\n",
    "    yaxis_title='R² Score (%)',\n",
    "    barmode='group'\n",
    ")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicted vs Actual\n",
    "best_predictions = best['predictions']\n",
    "\n",
    "compare_df = pd.DataFrame({\n",
    "    'Actual': y_test,\n",
    "    'Predicted': best_predictions,\n",
    "    'Error': np.abs(y_test - best_predictions)\n",
    "})\n",
    "\n",
    "fig = px.scatter(\n",
    "    compare_df,\n",
    "    x='Actual',\n",
    "    y='Predicted',\n",
    "    color='Error',\n",
    "    title=f'{best[\"Model\"]}: Predicted vs Actual',\n",
    "    labels={'Actual': 'Actual Delay (min)', 'Predicted': 'Predicted Delay (min)'},\n",
    "    color_continuous_scale='Reds',\n",
    "    opacity=0.6\n",
    ")\n",
    "\n",
    "min_val = min(compare_df['Actual'].min(), compare_df['Predicted'].min())\n",
    "max_val = max(compare_df['Actual'].max(), compare_df['Predicted'].max())\n",
    "\n",
    "fig.add_trace(go.Scatter(\n",
    "    x=[min_val, max_val],\n",
    "    y=[min_val, max_val],\n",
    "    mode='lines',\n",
    "    name='Perfect',\n",
    "    line=dict(dash='dash', color='black')\n",
    "))\n",
    "\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Error distribution\n",
    "compare_df['Residual'] = compare_df['Actual'] - compare_df['Predicted']\n",
    "\n",
    "fig = px.histogram(\n",
    "    compare_df,\n",
    "    x='Residual',\n",
    "    nbins=50,\n",
    "    title=f'{best[\"Model\"]}: Error Distribution',\n",
    "    labels={'Residual': 'Residual (min)'},\n",
    "    marginal='box'\n",
    ")\n",
    "fig.show()\n",
    "\n",
    "print(f\"\\nError Stats:\")\n",
    "print(f\"Mean: {compare_df['Residual'].mean():.2f}\")\n",
    "print(f\"Std: {compare_df['Residual'].std():.2f}\")\n",
    "print(f\"Median Abs: {compare_df['Error'].median():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance\n",
    "if best['Model'] in ['XGBoost', 'LightGBM', 'Random Forest']:\n",
    "    model_obj = best['model_obj']\n",
    "    importances = model_obj.feature_importances_\n",
    "    feature_names = X_train_encoded.columns.tolist()\n",
    "    \n",
    "    importance_df = pd.DataFrame({\n",
    "        'Feature': feature_names,\n",
    "        'Importance': importances\n",
    "    }).sort_values('Importance', ascending=False)\n",
    "    \n",
    "    print(f\"\\nTop 10 Features:\")\n",
    "    print(importance_df.head(10).to_string(index=False))\n",
    "    \n",
    "    fig = px.bar(\n",
    "        importance_df.head(15),\n",
    "        x='Importance',\n",
    "        y='Feature',\n",
    "        orientation='h',\n",
    "        title=f'Feature Importance - {best[\"Model\"]}'\n",
    "    )\n",
    "    fig.update_layout(yaxis={'categoryorder': 'total ascending'})\n",
    "    fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and encoders\n",
    "model_package = {\n",
    "    'model': best['model_obj'],\n",
    "    'encoders': encoders,\n",
    "    'feature_names': X_train_encoded.columns.tolist(),\n",
    "    'model_name': best['Model'],\n",
    "    'test_r2': best['Test_R2'],\n",
    "    'test_mae': best['Test_MAE']\n",
    "}\n",
    "\n",
    "with open('../modele_best.pkl', 'wb') as f:\n",
    "    pickle.dump(model_package, f)\n",
    "\n",
    "# Save historical stats for prediction time\n",
    "stats_package = {\n",
    "    'route_airline_stats': route_airline_stats,\n",
    "    'airline_stats': airline_stats,\n",
    "    'route_stats': route_stats,\n",
    "    'origin_stats': origin_stats,\n",
    "    'dest_stats': dest_stats\n",
    "}\n",
    "\n",
    "with open('../historical_stats.pkl', 'wb') as f:\n",
    "    pickle.dump(stats_package, f)\n",
    "\n",
    "print(f\"✓ {best['Model']} saved\")\n",
    "print(f\"✓ Test R²: {best['Test_R2']:.2f}%\")\n",
    "print(f\"✓ Test MAE: {best['Test_MAE']:.2f} min\")\n",
    "print(f\"✓ Historical stats saved for predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "This ML model:\n",
    "- Uses historical statistics as features\n",
    "- Trains on full dataset with variance\n",
    "- Works at booking time (no departure delay needed)\n",
    "- Uses XGBoost/LightGBM/Random Forest\n",
    "- Proper ML workflow for homework"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
